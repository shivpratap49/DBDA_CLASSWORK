{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspark pillow pandas pyarrow tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# prepare dataset using linux command - random 100 images from imagenette2\n",
    "mkdir -p ./data/images/mixed\n",
    "find ./imagenette2 -maxdepth 4 -type f | sort -R | head -100 | xargs -I{} cp {} ./data/images/mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/27 11:37:51 WARN Utils: Your hostname, nilesh-pc resolves to a loopback address: 127.0.1.1; using 192.168.1.101 instead (on interface wlp0s20f3)\n",
      "24/12/27 11:37:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/27 11:38:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "            .appName(\"image-ml\")\\\n",
    "            .config(\"spark.executor.memory\", \"1g\")\\\n",
    "            .config(\"spark.driver.memory\", \"6g\")\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 11:38:40.092024: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 11:38:40.137725: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:38:40.524034: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:38:40.526176: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 11:38:41.426352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image, ImageDraw\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import PandasUDFType, col, pandas_udf\n",
    "from pyspark.sql.types import (ArrayType, BinaryType, FloatType, IntegerType,\n",
    "                               StringType, StructField, StructType)\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------+------+-----+----+---------+\n",
      "|origin                                                            |height|width|mode|nChannels|\n",
      "+------------------------------------------------------------------+------+-----+----+---------+\n",
      "|file:///home/nilesh/newdemo/data/images/mixed/n02102040_1910.JPEG |375   |500  |16  |3        |\n",
      "|file:///home/nilesh/newdemo/data/images/mixed/n02102040_1078.JPEG |500   |377  |16  |3        |\n",
      "|file:///home/nilesh/newdemo/data/images/mixed/n01440764_11170.JPEG|333   |500  |16  |3        |\n",
      "|file:///home/nilesh/newdemo/data/images/mixed/n03417042_1840.JPEG |395   |500  |16  |3        |\n",
      "|file:///home/nilesh/newdemo/data/images/mixed/n03417042_6130.JPEG |389   |500  |16  |3        |\n",
      "+------------------------------------------------------------------+------+-----+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "images_dir = \"/home/nilesh/newdemo/data/images/mixed\"\n",
    "image_df = spark.read.format(\"image\").load(images_dir).filter(\"image.nChannels > 2 AND image.height < 1000\")\n",
    "image_df.printSchema()\n",
    "# to load binary data -- format=binaryFile\n",
    "# to load image data -- format=image\n",
    "image_df.select(\"image.origin\", \"image.height\", \"image.width\", \"image.mode\", \"image.nChannels\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_row = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:///home/nilesh/newdemo/data/images/mixed/n03417042_750.JPEG 16 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:104057): Atk-CRITICAL **: 11:42:00.753: atk_object_ref_state_set: assertion 'ATK_IS_OBJECT (accessible)' failed\n",
      "\n",
      "(eog:104057): Gtk-CRITICAL **: 11:42:00.753: gtk_accessible_get_widget: assertion 'GTK_IS_ACCESSIBLE (accessible)' failed\n"
     ]
    }
   ],
   "source": [
    "spark_single_img = image_df.select(\"image\").collect()[image_row]\n",
    "print(spark_single_img.image.origin, spark_single_img.image.mode, spark_single_img.image.nChannels )\n",
    "\n",
    "mode = 'RGBA' if (spark_single_img.image.nChannels == 4) else 'RGB' \n",
    "Image.frombytes(mode=mode, data=bytes(spark_single_img.image.data), size=[spark_single_img.image.width,spark_single_img.image.height]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:105073): Atk-CRITICAL **: 11:45:34.062: atk_object_ref_state_set: assertion 'ATK_IS_OBJECT (accessible)' failed\n",
      "\n",
      "(eog:105073): Gtk-CRITICAL **: 11:45:34.062: gtk_accessible_get_widget: assertion 'GTK_IS_ACCESSIBLE (accessible)' failed\n"
     ]
    }
   ],
   "source": [
    "def convert_bgr_array_to_rgb_array(img_array):\n",
    "    B, G, R = img_array.T\n",
    "    return np.array((R, G, B)).T\n",
    "\n",
    "img = Image.frombytes(mode=mode, data=bytes(spark_single_img.image.data), size=[spark_single_img.image.width,spark_single_img.image.height])\n",
    "\n",
    "converted_img_array = convert_bgr_array_to_rgb_array(np.asarray(img))\n",
    "Image.fromarray(converted_img_array).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(image_df.select(\"image.*\").schema.fields + [\n",
    "    StructField(\"data_as_resized_array\", ArrayType(IntegerType()), True),\n",
    "    StructField(\"data_as_array\", ArrayType(IntegerType()), True)\n",
    "])\n",
    "\n",
    "def resize_img(img_data, resize=True):\n",
    "    mode = 'RGBA' if (img_data.nChannels == 4) else 'RGB' \n",
    "    img = Image.frombytes(mode=mode, data=img_data.data, size=[img_data.width, img_data.height])\n",
    "    img = img.convert('RGB') if (mode == 'RGBA') else img\n",
    "    img = img.resize([224, 224], resample=Image.Resampling.BICUBIC) if (resize) else img\n",
    "    arr = convert_bgr_array_to_rgb_array(np.asarray(img))\n",
    "    arr = arr.reshape([224*224*3]) if (resize) else arr.reshape([img_data.width*img_data.height*3])\n",
    "    return arr\n",
    "\n",
    "def resize_image_udf(dataframe_batch_iterator: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    for dataframe_batch in dataframe_batch_iterator:\n",
    "        dataframe_batch[\"data_as_resized_array\"] = dataframe_batch.apply(resize_img, args=(True,), axis=1)\n",
    "        dataframe_batch[\"data_as_array\"] = dataframe_batch.apply(resize_img, args=(False,), axis=1)\n",
    "        yield dataframe_batch\n",
    "\n",
    "resized_df = image_df.select(\"image.*\").mapInPandas(resize_image_udf, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:105985): Atk-CRITICAL **: 11:48:28.703: atk_object_ref_state_set: assertion 'ATK_IS_OBJECT (accessible)' failed\n",
      "\n",
      "(eog:105985): Gtk-CRITICAL **: 11:48:28.703: gtk_accessible_get_widget: assertion 'GTK_IS_ACCESSIBLE (accessible)' failed\n",
      "\n",
      "(eog:105985): Atk-CRITICAL **: 11:48:28.703: atk_object_ref_state_set: assertion 'ATK_IS_OBJECT (accessible)' failed\n",
      "\n",
      "(eog:105985): Gtk-CRITICAL **: 11:48:28.703: gtk_accessible_get_widget: assertion 'GTK_IS_ACCESSIBLE (accessible)' failed\n"
     ]
    }
   ],
   "source": [
    "row = resized_df.collect()[image_row]\n",
    "\n",
    "Image.frombytes(mode='RGB', data=bytes(row.data_as_array), size=[row.width,row.height]).show()\n",
    "\n",
    "Image.frombytes(mode='RGB', data=bytes(row.data_as_resized_array), size=[224,224]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_array(arr):\n",
    "    return tf.keras.applications.resnet50.preprocess_input(arr.reshape([224,224,3]))\n",
    "\n",
    "@pandas_udf(ArrayType(FloatType()))\n",
    "def predict_batch_udf(iterator: Iterator[pd.Series]) -> Iterator[pd.Series]:\n",
    "    model = ResNet50()\n",
    "    for input_array in iterator:\n",
    "        normalized_input = np.stack(input_array.map(normalize_array))\n",
    "        preds = model.predict(normalized_input)\n",
    "        yield pd.Series(list(preds))\n",
    "\n",
    "predicted_df = resized_df.withColumn(\"predictions\", predict_batch_udf(\"data_as_resized_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 11:52:21.530334: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 11:52:21.536691: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:21.620306: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:21.621343: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 11:52:23.524776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-27 11:52:24.548041: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 11:52:24.552247: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:24.645320: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:24.646587: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 11:52:25.211968: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 11:52:25.215028: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:25.306827: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:25.307967: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 11:52:25.353899: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 11:52:25.357070: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:25.441809: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:25.442848: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 11:52:25.482548: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 11:52:25.485775: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:25.555884: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:25.556486: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 11:52:25.629017: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 11:52:25.631103: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:25.691892: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:25.692450: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 11:52:25.990157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-27 11:52:26.073848: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 11:52:26.076416: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:26.118147: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:26.118681: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 11:52:26.235370: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-27 11:52:26.239020: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:26.306565: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-27 11:52:26.307145: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-27 11:52:26.623839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-27 11:52:26.747290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-27 11:52:26.798337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-27 11:52:26.899294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-27 11:52:27.137016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-27 11:52:27.554686: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-27 11:52:28.404406: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-27 11:52:29.823777: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-27 11:52:30.389563: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-27 11:52:30.669836: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-27 11:52:30.949475: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-27 11:52:30.949491: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-27 11:52:30.949491: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-12-27 11:52:31.235056: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step                   (1 + 7) / 8]\n",
      "1/1 [==============================] - 6s 6s/step                   (2 + 6) / 8]\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 7s 7s/step\n",
      "1/1 [==============================] - 7s 7s/step                   (3 + 5) / 8]\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('n03417042', 'garbage_truck', 0.9985939860343933),\n",
       "  ('n03345487', 'fire_engine', 0.000993802328594029),\n",
       "  ('n04487081', 'trolleybus', 0.00013196909276302904),\n",
       "  ('n04467665', 'trailer_truck', 8.483155397698283e-05),\n",
       "  ('n04461696', 'tow_truck', 6.104258500272408e-05)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_row = predicted_df.collect()[image_row]\n",
    "\n",
    "tf.keras.applications.resnet50.decode_predictions(\n",
    "    np.array(prediction_row.predictions).reshape(1,1000), top=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
