{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.pipeline import PipelineModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/27 11:09:51 WARN Utils: Your hostname, nilesh-pc resolves to a loopback address: 127.0.1.1; using 192.168.1.101 instead (on interface wlp0s20f3)\n",
      "24/12/27 11:09:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/27 11:09:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/27 11:09:54 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .appName(\"demo03\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustID: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Salary: double (nullable = true)\n",
      " |-- Purchased: integer (nullable = true)\n",
      "\n",
      "+------+------+---+-------+---------+\n",
      "|CustID|Gender|Age| Salary|Purchased|\n",
      "+------+------+---+-------+---------+\n",
      "|     0|Female| 56|76000.0|        0|\n",
      "+------+------+---+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gender = \"Female\"     # input from user\n",
    "salary = 76000.0    # input from user\n",
    "age = 56            # input from user\n",
    "id = 0              # default values (not needed)\n",
    "purchased = 0       # default values (not needed)\n",
    "\n",
    "schema = \"CustID INT,Gender STRING,Age INT,Salary DOUBLE,Purchased INT\"\n",
    "df = spark.createDataFrame([\n",
    "    (id, gender, age, salary, purchased)\n",
    "], schema=schema)\n",
    "\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineModel_aab778d0df34\n"
     ]
    }
   ],
   "source": [
    "model = PipelineModel.load(\"file:///tmp/model2\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustID: integer (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Salary: double (nullable = true)\n",
      " |-- Purchased: integer (nullable = true)\n",
      " |-- GenderIndexed: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n",
      "+------+------+---+-------+---------+-------------+------------------+----------------------------------------+-----------------------------------------+----------+\n",
      "|CustID|Gender|Age|Salary |Purchased|GenderIndexed|features          |rawPrediction                           |probability                              |prediction|\n",
      "+------+------+---+-------+---------+-------------+------------------+----------------------------------------+-----------------------------------------+----------+\n",
      "|0     |Female|56 |76000.0|0        |0.0          |[56.0,76000.0,0.0]|[-3.2318994291554652,3.2318994291554652]|[0.037982780819716754,0.9620172191802833]|1.0       |\n",
      "+------+------+---+-------+---------+-------------+------------------+----------------------------------------+-----------------------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(df)\n",
    "\n",
    "predictions.printSchema()\n",
    "predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will Purchase\n"
     ]
    }
   ],
   "source": [
    "result = predictions.select(\"prediction\")\\\n",
    "    .first()\n",
    "\n",
    "if result[0] == 1.0:\n",
    "    print(\"Will Purchase\")\n",
    "else:\n",
    "    print(\"Will Not Purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
