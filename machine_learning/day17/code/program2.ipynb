{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "033722c2-e6a0-442c-80bd-d9be8d6e54b3",
   "metadata": {},
   "source": [
    "# RNN (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7910ca-30be-4685-9b26-1710d45530fa",
   "metadata": {},
   "source": [
    "## problem definition\n",
    "- text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9052339-25e0-4d94-9c29-ec7e33576c44",
   "metadata": {},
   "source": [
    "### import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28df1302-2c9b-4475-abd8-520be9240ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639b7ee0-1d67-4df7-89f7-6d5b28831bb5",
   "metadata": {},
   "source": [
    "### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198b23fb-3d40-4416-bb4e-bda19ddd66dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "# maxinum words per review = 10000\n",
    "(input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afa2c8f4-fffe-444d-b47c-3f4f8cb56b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the embeddings\n",
    "embeddings = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb37a5c4-3dab-4930-9ac6-205ea789f086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9514b80-628b-4385-a602-09d8358c8f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9485ac0-ee25-4b5c-9df9-a9dc09b88c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2217"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.get('product')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa8c949-2a10-4902-8467-b7a268ff6ad8",
   "metadata": {},
   "source": [
    "### pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dcb2eab-962f-40d1-b4ae-5ff069146ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "# reshaping the input_train with 1000 values\n",
    "input_train = sequence.pad_sequences(input_train, maxlen=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "117bee14-997f-4c99-9a1f-480302649c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   19,  178,   32],\n",
       "       [   0,    0,    0, ...,   16,  145,   95],\n",
       "       [   0,    0,    0, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4, 3586,    2],\n",
       "       [   0,    0,    0, ...,   12,    9,   23],\n",
       "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16932346-b3d3-4134-9e39-a71ae7607920",
   "metadata": {},
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b6d541d-fc70-4ac8-bb1e-11f5f3be36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "# create a model\n",
    "model = Sequential()\n",
    "\n",
    "# add embedding layer\n",
    "# 10000: max length of the words\n",
    "# 32: output length\n",
    "model.add(Embedding(10000, 32))\n",
    "\n",
    "# add simple RNN layer to connect all hidden layers to get output from previous layer\n",
    "model.add(LSTM(32))\n",
    "\n",
    "# add hidden layer\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(16))\n",
    "\n",
    "# add the output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f63b7b5-bcc1-4b9e-ae43-594c8d8b55bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 92s 116ms/step - loss: 0.3799 - accuracy: 0.8244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2df63e0d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(input_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5445f95-64fd-4fa6-aad7-8fa29b2c4816",
   "metadata": {},
   "source": [
    "### model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e913add0-2177-4c88-a43f-af5b0c88c038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# get the words and their embeddings\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def preprocess_review(review):\n",
    "    # Tokenize the review\n",
    "    tokens = word_tokenize(review.lower())\n",
    "    sequences = [word_index.get(word, 0) for word in tokens]\n",
    "    \n",
    "    # Pad the sequence\n",
    "    padded_sequence = pad_sequences([sequences], maxlen=1000)\n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83137f86-652e-45c2-b61c-077961bdeae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[array([[0.7271924]], dtype=float32), array([[0.65820765]], dtype=float32), array([[0.5647126]], dtype=float32), array([[0.6298438]], dtype=float32)]\n",
      "Review: \"I really loved this movie! It was fantastic.\" => Sentiment: Positive (Probability: 0.7272)\n",
      "Review: \"This was the worst film I have ever seen.\" => Sentiment: Positive (Probability: 0.6582)\n",
      "Review: \"this product worst\" => Sentiment: Positive (Probability: 0.5647)\n",
      "Review: \"this a very bad product\" => Sentiment: Positive (Probability: 0.6298)\n"
     ]
    }
   ],
   "source": [
    "# new reviews to predict the sentiment\n",
    "reviews = [\n",
    "    \"I really loved this movie! It was fantastic.\",\n",
    "    \"This was the worst film I have ever seen.\",\n",
    "    \"this product worst\",\n",
    "    \"this a very bad product\"\n",
    "]\n",
    "\n",
    "\n",
    "# convert all reviews to their embeddings\n",
    "preprocessed_reviews = [preprocess_review(review) for review in reviews]\n",
    "\n",
    "# predict each review using model\n",
    "predictions = [model.predict(review) for review in preprocessed_reviews]\n",
    "print(predictions)\n",
    "\n",
    "for review, pred in zip(reviews, predictions):\n",
    "    sentiment = 'Positive' if pred[0][0] > 0.5 else 'Negative'\n",
    "    print(f'Review: \"{review}\" => Sentiment: {sentiment} (Probability: {pred[0][0]:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f875ca-0d0a-4355-9751-2616c7ec0521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
