{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb6373e9-4428-40c5-864a-64881861dd68",
   "metadata": {},
   "source": [
    "# transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a29da37-4692-469a-9733-7d8138c67e03",
   "metadata": {},
   "source": [
    "### pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e33b503-785b-4c3f-bd38-797ed0b4cda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/homebrew/lib/python3.11/site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.11/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers) (2023.5.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install transformers\n",
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff05e89-0eb9-4a18-9c26-3d847985b3c2",
   "metadata": {},
   "source": [
    "### sentiment classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "073cc910-9c0a-4b5d-9261-30e5bd208e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f060e5-73a5-41e5-90d5-9dcd40763214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/opt/homebrew/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# create a pipeline for sentiment classification\n",
    "pipeline_sentiment_classification = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4231f7ce-e9b6-4624-aa19-0cd2ca73d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = [{'label': 'POSITIVE', 'score': 0.9998816251754761}]\n",
      "result = [{'label': 'NEGATIVE', 'score': 0.9997546076774597}]\n",
      "result = [{'label': 'NEGATIVE', 'score': 0.9997876286506653}]\n",
      "result = [{'label': 'NEGATIVE', 'score': 0.9997830986976624}]\n"
     ]
    }
   ],
   "source": [
    "reviews = [\n",
    "    \"I really loved this movie! It was fantastic.\",\n",
    "    \"This was the worst film I have ever seen.\",\n",
    "    \"this product worst\",\n",
    "    \"this a very bad product\"\n",
    "]\n",
    "for review in reviews:\n",
    "    # check the sentiment\n",
    "    result = pipeline_sentiment_classification(review)\n",
    "    print(f\"result = {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d467f5-f2bd-4a12-8b84-aa098da9af3f",
   "metadata": {},
   "source": [
    "### summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978e98cb-c1a5-459f-b4c8-a91dbefacb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/opt/homebrew/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/opt/homebrew/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipeline_summarization = pipeline('summarization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ee13ed-7ae9-4ca6-8b1d-3b9598334722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' It is the flagship publication of HT Media Limited, an entity controlled by the Birla family . It was founded by Sunder Singh Lyallpuri, founder-father of the Akali movement and the Shiromani Akali Dal, in Delhi . The Indian Readership Survey 2014 revealed that HT is the second-most widely read English newspaper in India after The Times of India .'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"\"\"\n",
    "Hindustan Times is an Indian English-language daily newspaper based in Delhi. It is the flagship publication of HT Media Limited, an entity controlled by the Birla family, and is owned by Shobhana Bhartia, the daughter of K. K. Birla.[2][3][4]\n",
    "It was founded by Sunder Singh Lyallpuri, founder-father of the Akali movement and the Shiromani Akali Dal, in Delhi and played integral roles in the Indian independence movement as a nationalist daily.[5][6][7]\n",
    "Hindustan Times is one of the largest newspapers in India by circulation. According to the Audit Bureau of Circulations, it has a circulation of 993,645 copies as of November 2017.[1] The Indian Readership Survey 2014 revealed that HT is the second-most widely read English newspaper in India after The Times of India.[8] It is popular in North India, with simultaneous editions from New Delhi, Mumbai, Lucknow, Patna, Ranchi and Chandigarh.\n",
    "\"\"\"\n",
    "pipeline_summarization(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c31ea3-2a61-4b98-a2f1-b4797a3b77be",
   "metadata": {},
   "source": [
    "### text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c98a82-8d1c-4b4b-a4eb-7809941dc507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 6c0e608 (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/opt/homebrew/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "pipeline_generation = pipeline('text-generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df7ec68-be4f-40f0-a49b-d06ad258ad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"machine learning is nice field to work in. But let's be honest here. As far as cognitive science is concerned, it's just a lot harder to tell when it's time to do it. Some areas of computing are still being implemented â€” the\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"machine learning is nice field to work in.\"\n",
    "pipeline_generation(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
